{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MINE 4201 - Laboratorio 2: Filtrado por Contenido y Estrategias de Embedding\n",
    "\n",
    "En este laboratorio exploraremos los sistemas de recomendación basados en contenido, utilizando diferentes estrategias de representación vectorial (embeddings) para describir los ítems:\n",
    "\n",
    "1. **TF-IDF** (Term Frequency – Inverse Document Frequency)\n",
    "2. **Word2Vec** (Representaciones densas aprendidas)\n",
    "\n",
    "Al finalizar, el estudiante será capaz de:\n",
    "- Construir una matriz documento-término y calcular TF-IDF\n",
    "- Aplicar selección de características para mejorar la representación\n",
    "- Entrenar y evaluar un modelo de clasificación para recomendación por contenido\n",
    "- Comprender el modelo Word2Vec y sus arquitecturas (Skip-gram, CBOW)\n",
    "- Comparar las representaciones TF-IDF vs Word2Vec para filtrado por contenido\n",
    "- Reflexionar sobre cómo estas estrategias de embedding se conectan con el Filtrado Colaborativo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Contexto: Filtrado por Contenido vs Filtrado Colaborativo\n",
    "\n",
    "En los sistemas de recomendación existen dos grandes familias de enfoques:\n",
    "\n",
    "| Enfoque | Descripción | Datos que utiliza |\n",
    "|---|---|---|\n",
    "| **Filtrado por Contenido** | Recomienda ítems similares a los que el usuario ha preferido, basándose en las **características del ítem** (género, descripción, conceptos). | Atributos / features de los ítems |\n",
    "| **Filtrado Colaborativo** | Recomienda ítems que usuarios similares han preferido, sin necesitar características del ítem. | Matriz de interacciones usuario-ítem |\n",
    "\n",
    "### ¿Dónde entran los Embeddings?\n",
    "\n",
    "Las estrategias de embedding (TF-IDF, Word2Vec, etc.) pueden utilizarse en **ambos** enfoques:\n",
    "\n",
    "- **En filtrado por contenido:** se usan para representar las características de los ítems en un espacio vectorial continuo. Es lo que haremos en la primera parte de este laboratorio.\n",
    "- **En filtrado colaborativo:** los embeddings pueden representar usuarios e ítems en un espacio latente compartido (e.g., factorización de matrices, embeddings neurales). Modelos como Word2Vec han inspirado técnicas como **Item2Vec**, donde se trata la secuencia de ítems consumidos por un usuario como una \"oración\" y se aprenden embeddings de ítems.\n",
    "\n",
    "En este laboratorio nos centraremos en el **filtrado por contenido** usando TF-IDF y exploraremos Word2Vec como estrategia alternativa de representación.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VnmkMaHMrV-P"
   },
   "source": [
    "Los sistemas de recomendación basados en contenido filtran contenido basado en la representación de items y el perfil del usuario. En este laboratorio trabajaremos con un conjunto de datos del sitio web [LibraryThing](https://https://www.librarything.com/).\n",
    "\n",
    "\n",
    "## Preparación del entorno\n",
    "Instale las librerias que vamos a utilizar e importelas en el ambiente de ejecución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j2IE3mtIuoLG"
   },
   "outputs": [],
   "source": [
    "!pip install scikit-learn\n",
    "!pip install pandas\n",
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kc5uvt4FwPeY"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yqQtNiS4vCJ8"
   },
   "source": [
    "## Carga de archivos\n",
    "\n",
    "Copie el archivo del dataset en el entorno colab en la pestaña files (la carpeta en el menú de la izquierda), carguemos el csv en un dataframe de pandas y revisemos su contenido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hBgLrcbXu4VV"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('DB-BOOK-content.csv') :\n",
    "  raise ValueError('El archivo DB-BOOK-content.csv no fue encontrado en el path')\n",
    "else:\n",
    "  print(\"Los archivos han sido cargados\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7RA_mj5ZxN8w"
   },
   "outputs": [],
   "source": [
    "df_dbbook=pd.read_csv('DB-BOOK-content.csv', sep=';')\n",
    "df_dbbook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wB8U14SC_qzm"
   },
   "source": [
    "Este dataset tiene un formato similar al que manejamos el taller pasado. Tiene una columna con el id del usuario, otra con el id del item y un rating.\n",
    "\n",
    "Cada rating esta presente varias veces, una por cada característica de los libros, revisemos por ejemplo las características del libro con ID 8010.\n",
    "\n",
    "Se selecciona del dataframe las columnas name, featureID y featureShortname, la instruccion drop_duplicates nos deja solamente las columnas que no\n",
    "\n",
    "Nota: Para saber más de indexación de dataframes de pandas utilizando .loc hay una explicación en la [documentación](https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-K8PljKX8MhJ"
   },
   "outputs": [],
   "source": [
    "df_dbbook.loc[df_dbbook.DBbook_ItemID==8010,['DBbook_ItemID','name','featureID','featureShortname']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hxv8YvaiMrPM"
   },
   "source": [
    "Cada libro tiene features que fueron extraidos de [DBpedia](https://wiki.dbpedia.org/). Dbpedia es una iniciativa para construir una representación de conceptos y relaciones mediante ontologías utilizando la información depositada en wikipedia. Más adelante vamos a utilizar DBPedia para otros talleres que aprovechan la información de la ontología de DBPedia, por ahora lo que tenemos es una representación de conjunto de palabras (o conceptos) para describir un item.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AeZn60fcT-OC"
   },
   "source": [
    "## Creación de matriz documento-termino\n",
    "\n",
    "En las siguientes líneas vamos a crear la matriz documento término, el primer paso es obtener en un dataframe los libros, los conceptos, y  los conceptos únicos por libro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8y198APzhd8U"
   },
   "outputs": [],
   "source": [
    "df_libros=df_dbbook.loc[:,['DBbook_ItemID','name']].drop_duplicates()\n",
    "df_libros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kMxSgYFeh5xC"
   },
   "outputs": [],
   "source": [
    "df_conceptos=df_dbbook.loc[:,['featureID','featureShortname']].drop_duplicates()\n",
    "df_conceptos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tXWiCYifMqnr"
   },
   "outputs": [],
   "source": [
    "df_libros_concepto=df_dbbook.loc[:,['DBbook_ItemID','name','featureID','featureShortname']].drop_duplicates()\n",
    "df_libros_concepto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yCw8uuvAXylr"
   },
   "source": [
    "Se quiere obtener una martiz que tenga como filas cada uno de los libros, y como columnas cada uno de los conceptos, y en cada coordenada un 1 si esta presente el concepto y 0 de lo contrario. A esta operación se le conoce como pivot de una tabla.\n",
    "\n",
    "La función [pivot](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.pivot.html) toma tres parámetros: la columna del dataframe original que va a tomar el índice de las filas del nuevo dataframe (index), la columna del dataframe original mediante la cual se van a generar las columnas (columns) y values los valores con los cuales se va a llenar el dataframe, en este caso  vamos a dejar momentaneamente el id del feature para indicar que existe.\n",
    "\n",
    "Finalmente aplicamos la función [notna](https://pandas.pydata.org/docs/reference/api/pandas.notna.html) para modificar uno a uno los elementos de la matriz\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_matriz_libros_concepto = (\n",
    "    df_libros_concepto[['DBbook_ItemID', 'featureID']]\n",
    "      .drop_duplicates()\n",
    "      .pivot(index='DBbook_ItemID', columns='featureID', values='featureID')\n",
    "      .notna()              # vectorized (fast)\n",
    "      .astype('int8')       # 1/0 in int8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matriz_libros_concepto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TkPuSt24UTCF"
   },
   "outputs": [],
   "source": [
    "df_matriz_libros_concepto.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qbHHztT_OI8f"
   },
   "source": [
    "En la siguiente celda se está aplicando la función [sumatoria](https://www.geeksforgeeks.org/python-pandas-dataframe-sum/) por eje al dataframe anterior, por defecto el eje es 0, por lo que generará una Serie (vector) del tamaño de las columnas y por cada columna calculará la sumatoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kzOcvNAR9h_J"
   },
   "outputs": [],
   "source": [
    "help(pd.DataFrame.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TuhKo_lLZd4U"
   },
   "outputs": [],
   "source": [
    "series_suma=df_matriz_libros_concepto.sum()\n",
    "series_suma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ceDsHNaXTlYk"
   },
   "source": [
    "El objeto series_suma no es un dataframe sino un objeto tipo Series, que es un arreglo. Un dataframe puede ser visto como una concatenación de varios objetos de tipo Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BqIJoQulTdhW"
   },
   "outputs": [],
   "source": [
    "type(series_suma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mDO_1AqmfAXq"
   },
   "source": [
    "**Interprete las siguientes figuras y diga qué quieren decir en términos del número de items y de características asignadas a los items**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k0e3niVqdRU7"
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x=range(0,len(series_suma)) ,y=series_suma.sort_values() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RH9SPa1RcCg6"
   },
   "outputs": [],
   "source": [
    "series_suma_2=df_matriz_libros_concepto.sum(axis=1)\n",
    "series_suma_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AaVYz0MGd3hS"
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x=range(0, len(series_suma_2)), y=series_suma_2.sort_values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZECBhVmYikdo"
   },
   "source": [
    "# Cálculo de matriz tf-idf\n",
    "\n",
    "La matriz df_matriz_libros_concepto hasta el momento tiene en cada coordenada la presencia o ausencia de la característica que describe el atributo, este sería el término $\\text{tf}$ de la siguiente fórmula donde $i$ es un término o palabra y $d$ es un documento.\n",
    "\n",
    "$\\text{tfidf}_{i,d} = \\text{tf}_{i,d} \\cdot \\text{idf}_{i}$\n",
    "\n",
    "El Inverse Document Frequency esta definido como:\n",
    "\n",
    "$\\text{idf}_{i,d} = \\log \\frac{N}{\\text{df}_{i}}$\n",
    "\n",
    "Donde $\\text{df}_{t}$ es el número de documentos en los que aparece el término $i$ y N el número total de documentos\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "scSusoGhP-Y-"
   },
   "source": [
    "En python es posible operar vectores con escalares directamente, gracias a que por debajo python genera operaciones entre arreglos cuando operamos con un escalar mediante la operación de [broadcasting](https://jakevdp.github.io/PythonDataScienceHandbook/02.05-computation-on-arrays-broadcasting.html) Por ejemplo, el anterior arreglo se puede dividir entre 6, por debajo python genera un arreglo del mismo tamaño y realiza la operación elemento a elemento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QPaJm6-HNfng"
   },
   "outputs": [],
   "source": [
    "series_suma/6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vk8kecfgTTP7"
   },
   "source": [
    "En las siguientes celdas, cree un objeto tipo series llamado df_idf, que contiene el IDF de cada atributo. Puede utilizar la función [np.log2](https://docs.scipy.org/doc/numpy/reference/generated/numpy.log2.html) de numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FtKa4d7XTOEx"
   },
   "outputs": [],
   "source": [
    "df_idf=???\n",
    "df_idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tBQhrEL-U381"
   },
   "source": [
    "Si df_idf fue calculado correctamente, la siguiente instrucción multiplicará cada fila del dataframe elemento por elemento (element-wise) por la serie que contiene el IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mOq3GJd7UWs7"
   },
   "outputs": [],
   "source": [
    "df_matriz_tf_idf=df_matriz_libros_concepto.multiply(df_idf, axis=1)\n",
    "df_matriz_tf_idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zys6_IxogUAR"
   },
   "source": [
    "En el siguiente mapa de calor se observa el tf_idf de los items representados en las 300 características con mayor frecuencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gEVlmVrqh-PJ"
   },
   "outputs": [],
   "source": [
    "df_matriz_tf_idf.loc[:,series_suma.nlargest(300).index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YURPa2NuUsar"
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (15,15)\n",
    "sns.heatmap(df_matriz_tf_idf.loc[:,series_suma.nlargest(300).index],cmap=\"Blues\", vmin=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sQnyh7YmlhQA"
   },
   "source": [
    "**¿Qué puede interpretar sobre la figura anterior?\n",
    "Encuentre los nombres de las características más frecuentes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HESUWI7Wn3Dw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bIx0A7I4n3Q-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ljppu_vUm_S2"
   },
   "source": [
    "# Selección de características\n",
    "\n",
    "Una vez realizado el proceso de indexamiento, se puede realizar el proceso de selección de características.\n",
    "\n",
    "En este momento contamos con más de 12 mil conceptos. ¿Con cuántos vale la pena crear los modelos de filtrado?\n",
    "\n",
    "El paso más simple es filtrar las características con baja frecuencia dentro del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v5aqEuxwYKRZ"
   },
   "outputs": [],
   "source": [
    "series_suma.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dzO-nEUjp8EX"
   },
   "source": [
    "**¿Qué puede decir sobre la distribución de frecuencia de las características en los items? ¿Vale la pena tener todas las características que tenemos actualmente?**\n",
    "\n",
    ".\n",
    "**Retire de la matriz df_matrix_tf_idf las columnas que representan a los items que tienen menos de 3 items asociados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_HrDjFGNp6tf"
   },
   "outputs": [],
   "source": [
    "# Se filtra la serie por aquellos que tienen al menos 3\n",
    "series_suma[series_suma>=3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N_96kKMLowAz"
   },
   "outputs": [],
   "source": [
    "df_matriz_tf_idf=???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c9oTh99Ksd2E"
   },
   "outputs": [],
   "source": [
    "df_matriz_tf_idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PLrz5tmBsn3G"
   },
   "source": [
    "### Para las siguientes estrategias de selección de características, tenemos que aplicar técnicas supervisadas (que conocen la clase a predecir o lo que se quiere pronosticar), para esto tenemos que retomar nuestro dataset original de interacciones entre usuarios e items para asignar la etiqueta (le gustó/ no le gustó)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L7LPIbBrskLy"
   },
   "outputs": [],
   "source": [
    "# Recordemos como es el dataset original.\n",
    "df_dbbook.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tYJ9ei1auLxc"
   },
   "source": [
    "Creemos un dataframe para crear un dataset de un sistema de recomendación como el visto en el laboratorio pasado (una única interacción de tipo usuario, item y rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4ANyHv11thhi"
   },
   "outputs": [],
   "source": [
    "df_all_interactions=df_dbbook[['DBbook_userID','DBbook_ItemID','rate']].drop_duplicates()\n",
    "df_all_interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xsyZc8bXvMLN"
   },
   "source": [
    "Para asignar una clase, se binarizan los ratings. Una regla simple es calcular el rating promedio por persona. Todo lo que esté por debajo del promedio se clasifica como no le gusta, igual o por encima es si le gusta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AYFPgnafuvOR"
   },
   "outputs": [],
   "source": [
    "df_user_mean=df_all_interactions.groupby('DBbook_userID')['rate'].mean().reset_index()\n",
    "df_user_mean.columns=['DBbook_userID','mean']\n",
    "df_user_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cUjFc_W2xWKE"
   },
   "source": [
    "**Realice un merge entre df_all_interactions y df_user_mean, asignando su resultado a df_all_interactions.\n",
    "Cree una nueva columna en el dataframe df_all_interactions llamada 'class' con True si el rating del usuario es mayor o igual a su promedio**\n",
    "\n",
    "[Documentación pandas merge](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html)\n",
    "\n",
    "[Tutorial creación de columnas a partir del valor de otras](https://thispointer.com/python-pandas-how-to-add-new-columns-in-a-dataframe-using-or-dataframe-assign/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cFalHJy4wiZA"
   },
   "outputs": [],
   "source": [
    "df_all_interactions=???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HpR5vLBsxTyS"
   },
   "outputs": [],
   "source": [
    "df_all_interactions['class']=???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2jrhOGwJyJtw"
   },
   "outputs": [],
   "source": [
    "df_all_interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g0TaHQ5UzBAM"
   },
   "source": [
    "Por último, se procede a partir el dataset en entrenamiento y test. Se utiliza de la librería sklearn la función [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html).\n",
    "\n",
    "Esta recibe como parámetro el dataset a partir, el porcentaje para test y un parámetro que indica la variable por la cual estratificar la partición, en este caso quisieramos que las interacciones en test sean de usuarios que vimos en train, por lo tanto se deja estratificado por usuario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_qjRBWLK9ag3"
   },
   "outputs": [],
   "source": [
    "help(train_test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A_rJHAXnyQOQ"
   },
   "outputs": [],
   "source": [
    "#Para garantizar reproducibilidad en resultados\n",
    "seed = 10\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "df_all_interactions_train, df_all_interactions_test =train_test_split(df_all_interactions, test_size=0.2, stratify=df_all_interactions['DBbook_userID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wm7RE_HE029u"
   },
   "outputs": [],
   "source": [
    "df_all_interactions_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gol-lLxk04KP"
   },
   "outputs": [],
   "source": [
    "df_all_interactions_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IHo1of0bOsac"
   },
   "outputs": [],
   "source": [
    "df_all_interactions_train.DBbook_userID.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OkwMwoKlOgkF"
   },
   "outputs": [],
   "source": [
    "df_all_interactions_test.DBbook_userID.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5h4TZuz5PFkU"
   },
   "outputs": [],
   "source": [
    "df_conteos_usuario_train_test=pd.concat([df_all_interactions_train.DBbook_userID.value_counts(),df_all_interactions_test.DBbook_userID.value_counts()],axis=1)\n",
    "df_conteos_usuario_train_test.columns=['train_count','test_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W8xqph4MP99v"
   },
   "outputs": [],
   "source": [
    "df_conteos_usuario_train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xjlqB-nYQDtH"
   },
   "outputs": [],
   "source": [
    "df_conteos_usuario_train_test.nlargest(500,'test_count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lrz-WIwc6VKM"
   },
   "source": [
    "**Chi-cuadrado**\n",
    "\n",
    "La selección de características mediante la prueba [chi-cuadrado](https://en.wikipedia.org/wiki/Chi-squared_test) nos dice si la diferencia observada entre las frecuencias de co-ocurrencia de dos variables es significativa. La idea es seleccionar características que más ayuden a discriminar la clase objetivo observando la frecuencia en la que ocurren juntas.\n",
    "\n",
    "La librería sklearn permite identificar la importancia de cada una de las variables utilizando el método [chi2](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.chi2.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z2VftVGI06T-"
   },
   "outputs": [],
   "source": [
    "help(chi2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GqPWbi5c-GH2"
   },
   "source": [
    "En filtrado por contenido, se arma un modelo por usuario. Por ahora vamos a escoger las características más importantes para el primer usuario del dataset de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_0cAoMuU9XJ7"
   },
   "outputs": [],
   "source": [
    "#Debería dar 2817\n",
    "primer_usuario_id=df_all_interactions_test.iloc[0]['DBbook_userID']\n",
    "primer_usuario_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YhSkCDyc-f_A"
   },
   "source": [
    "Obtengamos los ids de los items con los que ha interactuado y su opinion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7sHn5myK9ttr"
   },
   "outputs": [],
   "source": [
    "df_temporal_usuario=df_all_interactions_train.loc[df_all_interactions_train.DBbook_userID==1124,['DBbook_ItemID','class']]\n",
    "df_temporal_usuario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x3olsl9JAiqf"
   },
   "source": [
    "Peguemos a este dataframe la representación vectorial de tf_idf por el id del item, en la matriz es el índice de las filas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n-baZRsWAdSa"
   },
   "outputs": [],
   "source": [
    "df_temporal_usuario=df_temporal_usuario.merge(df_matriz_tf_idf, how='left', left_on='DBbook_ItemID', right_index=True)\n",
    "df_temporal_usuario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OeUVr32EBVHf"
   },
   "source": [
    "Este dataframe representa los datos de entrenamiento del modelo para predicción de una clase binaria (class True es le gusta, class False es no le gusta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cg9LICZ8EY_Y"
   },
   "outputs": [],
   "source": [
    "#vamos a indexar solamente las columnas que son características, la prueba chi2 lo compara todas las características contra la clase objetivo\n",
    "features=df_matriz_tf_idf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wLtYVC6bBKAq"
   },
   "outputs": [],
   "source": [
    "pesos_chi2, pval= chi2(df_temporal_usuario[features],df_temporal_usuario['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A-yWyvKqCq4J"
   },
   "outputs": [],
   "source": [
    "#La prueba puede arrojar nan\n",
    "pesos_chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TTetd36rCtNZ"
   },
   "outputs": [],
   "source": [
    "pval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lcG-LgPJEjBZ"
   },
   "outputs": [],
   "source": [
    "# LLenamos con peso 0 los que no se pudieron calcular\n",
    "pesos_chi2=np.nan_to_num(pesos_chi2)\n",
    "pesos_chi2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KtzHpO7GGl7A"
   },
   "source": [
    "Se crea una máscara de indexación con los valores que son positivos según la prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WJaQ-BTcFgzI"
   },
   "outputs": [],
   "source": [
    "pesos_chi2_mask=pesos_chi2>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NV5CGeWjGdMY"
   },
   "outputs": [],
   "source": [
    "pesos_chi2_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BN2UPiY8GekY"
   },
   "outputs": [],
   "source": [
    "features[pesos_chi2_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3jRpP0WyIwPk"
   },
   "source": [
    "El siguiente sería el resultado, se recortaron las columnas de pesos del usuario, dejando 119 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eqQWy2JjGxUY"
   },
   "outputs": [],
   "source": [
    "df_temporal_usuario.loc[:,features[pesos_chi2_mask]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0A9R37kVIrzE"
   },
   "outputs": [],
   "source": [
    "del df_temporal_usuario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XLUTb5TxI7kv"
   },
   "source": [
    "**Complete el código de la siguiente celda, el objetivo es crear un diccionario donde la llave es el id del usuario y el valor es un arreglo con los features seleccionados para el usuario**\n",
    "\n",
    "El proceso que implementamos no esta optimizado, por lo que vamos a armar el modelo solamente para los 500 usuarios con más ratings en el dataset de test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T8EUnhJDIjTt"
   },
   "outputs": [],
   "source": [
    "diccionario_usuarios_features={}\n",
    "# 500 usuarios con más ratings en test\n",
    "unique_users_test=df_conteos_usuario_train_test.nlargest(500,'test_count').index\n",
    "i=0\n",
    "print(unique_users_test.shape)\n",
    "for user in unique_users_test:\n",
    "  if not user in diccionario_usuarios_features:\n",
    "    df_temporal_usuario=df_all_interactions_train.loc[df_all_interactions_train.DBbook_userID==user,['DBbook_ItemID','class']]\n",
    "\n",
    "    df_temporal_usuario=df_temporal_usuario.merge ????\n",
    "\n",
    "    pesos_chi2, pval=????\n",
    "    pesos_chi2=np.nan_to_num(pesos_chi2)\n",
    "    pesos_chi2_mask=pesos_chi2>0\n",
    "    features_usuario=features[pesos_chi2_mask]\n",
    "    diccionario_usuarios_features[user]=features_usuario\n",
    "    i=i+1\n",
    "    if i%50==0:\n",
    "      print(i)\n",
    "    del df_temporal_usuario\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n3go4ywZJOSX"
   },
   "outputs": [],
   "source": [
    "len(diccionario_usuarios_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y1OwnizDbVBG"
   },
   "outputs": [],
   "source": [
    "diccionario_usuarios_features.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hFT8FbvPT4bD"
   },
   "source": [
    "Otro criterio que puede ser usado es [Mutual Information](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_classif.html#sklearn.feature_selection.mutual_info_classif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2kHhHH-_UIn3"
   },
   "source": [
    "# Modelo de recomendación y evaluación\n",
    "\n",
    "Una vez seleccionadas las características por usuario, se puede usar el dataset de entrenamiento para aprender un modelo de clasificación binaria y probarlo sobre test.\n",
    "\n",
    "Uno de los modelos que puede ser utilizado es el [clasificador por vecinos más cercanos](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm).\n",
    "\n",
    "Cada usuario tiene unas instancias representadas en un espacio vectorial del tamaño de las características seleccionadas anteriormente. Para una nueva instancia (predicción) se mira cuáles son los k vecinos más cercanos a ese dato nuevo y se predice la clase mayoritaria dentro del grupo de los vecinos. Observe el siguiente ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hmb-n1W-W5Ch"
   },
   "outputs": [],
   "source": [
    "%%html\n",
    "<iframe src=\"https://es.wikipedia.org/wiki/K_vecinos_m%C3%A1s_pr%C3%B3ximos#/media/Archivo:KnnClassification.svg\" width=\"1200\" height=\"600\"></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kKdEp0MiZ1WL"
   },
   "source": [
    "Tomemos como ejemplo el usuario 3852, armemos su conjunto de entrenamiento. Note que se estan seleccionando solamente los features calculados en el punto anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wLTrU3RBSQ-p"
   },
   "outputs": [],
   "source": [
    "usuario_id = 3852\n",
    "if usuario_id not in diccionario_usuarios_features:\n",
    "    usuario_id = next(iter(diccionario_usuarios_features))\n",
    "    print(f\"Usuario 3852 no disponible en entrenamiento. Se usa usuario {usuario_id}.\")\n",
    "\n",
    "features_usuario = diccionario_usuarios_features[usuario_id]\n",
    "df_temporal_usuario_train = df_all_interactions_train.loc[\n",
    "    df_all_interactions_train.DBbook_userID == usuario_id, ['DBbook_ItemID', 'class']\n",
    " ]\n",
    "df_temporal_usuario_train = df_temporal_usuario_train.merge(\n",
    "    df_matriz_tf_idf[features_usuario], how='left', left_on='DBbook_ItemID', right_index=True\n",
    ")\n",
    "df_temporal_usuario_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W77A4lUtbysX"
   },
   "source": [
    "Armamos de igual forma el conjunto de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HKOUVPhbbpAg"
   },
   "outputs": [],
   "source": [
    "df_temporal_usuario_test = df_all_interactions_test.loc[\n",
    "    df_all_interactions_test.DBbook_userID == usuario_id, ['DBbook_ItemID', 'class']\n",
    " ]\n",
    "df_temporal_usuario_test = df_temporal_usuario_test.merge(\n",
    "    df_matriz_tf_idf[features_usuario], how='left', left_on='DBbook_ItemID', right_index=True\n",
    ")\n",
    "df_temporal_usuario_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eRzxc7DZdWhS"
   },
   "source": [
    "Utilizaremos la clase [KNeighborsClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) de scikit-learn para hacer la predicción de los datos del conjunto de test. El modelo tiene 3 métodos principales. El constructor permite inicializar el k a usar, la métrica entre otros; fit sirve para darle los datos de entrenamiento base al modelo; y predict para predecir los datos que se le pasan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nLrsiGFqe4MQ"
   },
   "outputs": [],
   "source": [
    "#Con esta configuración se utilizan los 3 vecinos más cercanos, con distancia euclidiana\n",
    "knn_clasif=KNeighborsClassifier(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zk--tT6ScodK"
   },
   "outputs": [],
   "source": [
    "# Fit recibe la matriz de entrenamiento y la clase objetivo\n",
    "knn_clasif.fit(df_temporal_usuario_train[features_usuario], df_temporal_usuario_train['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MzXkT1mngNJ4"
   },
   "outputs": [],
   "source": [
    "# llamamos predict sobre  los test , creando una nueva columna en el dataframe de test\n",
    "df_temporal_usuario_test['predict']=knn_clasif.predict(df_temporal_usuario_test[features_usuario])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qQxjEKRShJhV"
   },
   "outputs": [],
   "source": [
    "df_temporal_usuario_test[['DBbook_ItemID','class','predict']].merge(df_libros, how='left', on='DBbook_ItemID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s6uiIgPKjtuf"
   },
   "source": [
    "**En las siguientes celdas realice hipótesis sobre por qué falló la clasificación para estos items y por qué funcionó para los otros, revise los conceptos seleccionados para el usuario y los asociados a los items**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wpTjHFrWj_RO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xagX9J6kj_bi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u6DXNlhwTq5Z"
   },
   "source": [
    "Finalmente, la librería sklearn tiene diferentes métricas de evaluación de clasificación. En particular podemos calcular la matriz de confusión de la clasificación utilizando la función [confusion_matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html), y el cálculo de las métricas precision, recall, y f1 con la función [precision_recall_fscore_support](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gQLtbeNMlFME"
   },
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(df_temporal_usuario_test['class'],df_temporal_usuario_test['predict'], labels=[False,True]).ravel()\n",
    "\n",
    "(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ql_O4aBalNay"
   },
   "outputs": [],
   "source": [
    "precision_recall_fscore_support(df_temporal_usuario_test['class'],df_temporal_usuario_test['predict'], pos_label=True,average='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "96Bh3YlFmuo0"
   },
   "source": [
    "**Ejercicio: Realice las predicciones binarias para los usuarios en el conjunto de test a los que se les hizo la selección de características, mida la precisión, el recall y f_score de su modelo con las predicciones realizadas y ajústelo cambiando el k**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h0Z-k78WmU8G"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Parte 2: De TF-IDF a Embeddings Densos — Introducción a Word2Vec\n",
    "\n",
    "Hasta aquí hemos trabajado con representaciones **dispersas** (sparse) basadas en TF-IDF. Estas tienen algunas limitaciones:\n",
    "\n",
    "- **Alta dimensionalidad:** la matriz tiene miles de columnas (una por concepto)\n",
    "- **Dispersión:** la mayoría de los valores son cero\n",
    "- **Sin semántica:** dos conceptos sinónimos tienen columnas diferentes y no hay relación entre ellos\n",
    "\n",
    "Las representaciones **densas** (como Word2Vec) resuelven estos problemas al aprender vectores de baja dimensionalidad donde conceptos similares están cerca en el espacio vectorial.\n",
    "\n",
    "A continuación exploraremos paso a paso cómo funciona Word2Vec."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio de reflexión: TF-IDF vs Embeddings Densos\n",
    "\n",
    "Antes de continuar con Word2Vec, reflexione sobre las siguientes preguntas:\n",
    "\n",
    "1. ¿Qué ventajas y desventajas tiene la representación TF-IDF que utilizamos para los libros?\n",
    "2. ¿Qué pasaría si dos libros tratan del mismo tema pero usan conceptos diferentes en DBpedia?\n",
    "3. ¿Cómo cree que un embedding denso podría mejorar las recomendaciones?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escriba sus respuestas como comentarios o en celdas markdown adicionales\n",
    "# Respuesta 1:\n",
    "\n",
    "# Respuesta 2:\n",
    "\n",
    "# Respuesta 3:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a114b3e0",
   "metadata": {},
   "source": [
    "## 1. Configuración Inicial\n",
    "\n",
    "Primero importamos las librerías necesarias y configuramos el logging para ver el progreso del entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953aae7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f395263",
   "metadata": {},
   "source": [
    "## 2. ¿Por Qué Necesitamos Representar Palabras como Vectores?\n",
    "\n",
    "Las computadoras no entienden texto directamente — necesitan números. La pregunta clave es: **¿cómo convertimos palabras en números de forma que se preserve su significado?**\n",
    "\n",
    "### 2.1 El Modelo Bolsa de Palabras (Bag-of-Words)\n",
    "\n",
    "El enfoque más simple es el modelo **Bolsa de Palabras** (*Bag-of-Words*). Este transforma cada documento en un vector de longitud fija donde cada elemento cuenta cuántas veces aparece una palabra.\n",
    "\n",
    "**Ejemplo:** Dadas las oraciones:\n",
    "- *\"Juan quiere ver películas. María quiere películas también.\"*\n",
    "- *\"Juan también quiere ver fútbol. María odia el fútbol.\"*\n",
    "\n",
    "El modelo genera vectores como:\n",
    "- `[1, 2, 1, 1, 2, 1, 1, 0, 0, 0, 0]`\n",
    "- `[1, 1, 1, 1, 0, 1, 0, 1, 2, 1, 1]`\n",
    "\n",
    "Donde cada posición corresponde a una palabra del vocabulario.\n",
    "\n",
    "### 2.2 Limitaciones de la Bolsa de Palabras\n",
    "\n",
    "Este enfoque tiene **dos problemas fundamentales**:\n",
    "\n",
    "1. **Pierde el orden de las palabras:** \"Juan quiere a María\" y \"María quiere a Juan\" producen vectores idénticos, aunque significan cosas distintas.\n",
    "\n",
    "2. **No captura el significado:** Las palabras \"bueno\" y \"excelente\" podrían estar tan lejos en el espacio vectorial como \"bueno\" y \"zapato\", a pesar de que las dos primeras son sinónimos.\n",
    "\n",
    "**Word2Vec resuelve el segundo problema:** aprende representaciones donde palabras con significados similares están cerca en el espacio vectorial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1170a188",
   "metadata": {},
   "source": [
    "## 3. ¿Cómo Funciona Word2Vec?\n",
    "\n",
    "Word2Vec es un algoritmo basado en redes neuronales superficiales (*shallow neural networks*) que aprende representaciones vectoriales de palabras a partir de grandes cantidades de texto.\n",
    "\n",
    "### 3.1 La Idea Central\n",
    "\n",
    "> **\"Conocerás una palabra por la compañía que mantiene\"** — J.R. Firth, 1957\n",
    "\n",
    "Word2Vec se basa en la **hipótesis distribucional**: palabras que aparecen en contextos similares tienden a tener significados similares. Por ejemplo, \"perro\" y \"gato\" aparecen frecuentemente con palabras como \"mascota\", \"veterinario\", \"comida\", etc.\n",
    "\n",
    "### 3.2 Las Dos Arquitecturas\n",
    "\n",
    "Word2Vec tiene dos variantes:\n",
    "\n",
    "#### Skip-gram (SG)\n",
    "- **Entrada:** una palabra central\n",
    "- **Salida:** predice las palabras del contexto (vecinas)\n",
    "- Ejemplo: dada la palabra \"gato\", predice \"el\", \"come\", \"pescado\"\n",
    "- Funciona mejor con corpus pequeños y palabras poco frecuentes\n",
    "\n",
    "#### Continuous Bag-of-Words (CBOW)\n",
    "- **Entrada:** las palabras del contexto\n",
    "- **Salida:** predice la palabra central\n",
    "- Ejemplo: dadas \"el\", \"come\", \"pescado\", predice \"gato\"\n",
    "- Es más rápido de entrenar y funciona bien con palabras frecuentes\n",
    "\n",
    "### 3.3 ¿Qué aprende la red?\n",
    "\n",
    "La red neuronal tiene una capa oculta. Los **pesos de la capa de proyección** (entre la entrada y la capa oculta) son los **vectores de las palabras** (embeddings). Si la capa oculta tiene 300 neuronas, obtendremos embeddings de 300 dimensiones.\n",
    "\n",
    "El resultado son vectores con propiedades algebraicas notables, como:\n",
    "\n",
    "- `vec(\"rey\") - vec(\"hombre\") + vec(\"mujer\") ≈ vec(\"reina\")`\n",
    "- `vec(\"París\") - vec(\"Francia\") + vec(\"Japón\") ≈ vec(\"Tokio\")`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa29d635",
   "metadata": {},
   "source": [
    "## 4. Demostración con un Modelo Pre-entrenado\n",
    "\n",
    "Antes de entrenar nuestro propio modelo, veamos qué puede hacer Word2Vec usando un modelo ya entrenado con parte del dataset de Google News (~3 millones de palabras y frases).\n",
    "\n",
    "> **Nota:** El modelo pesa aproximadamente 2GB. Si no tienes buena conexión, puedes saltar a la sección 5 (Entrenar tu propio modelo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df5f673",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install gensim\n",
    "%pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1329fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "# Descargamos el modelo pre-entrenado de Google News (300 dimensiones)\n",
    "wv = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05dc66fe",
   "metadata": {},
   "source": [
    "### 4.1 Explorar el Vocabulario\n",
    "\n",
    "Podemos ver las primeras palabras del vocabulario del modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747e5a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostramos las primeras 10 palabras del vocabulario\n",
    "for index, word in enumerate(wv.index_to_key):\n",
    "    if index == 10:\n",
    "        break\n",
    "    print(f\"Palabra #{index}/{len(wv.index_to_key)}: {word}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdf193f",
   "metadata": {},
   "source": [
    "### 4.2 Obtener el Vector de una Palabra\n",
    "\n",
    "Cada palabra está representada por un vector de 300 dimensiones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04e761f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos el vector de la palabra 'king'\n",
    "vec_king = wv['king']\n",
    "print(f\"Dimensiones del vector: {vec_king.shape}\")\n",
    "print(f\"Primeros 10 valores: {vec_king[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d28030",
   "metadata": {},
   "source": [
    "### 4.3 Palabras Desconocidas\n",
    "\n",
    "Una limitación de Word2Vec es que **no puede generar vectores para palabras que no están en su vocabulario**. Si necesitas manejar palabras desconocidas, considera usar **FastText**, que trabaja con sub-palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ace56e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intentamos obtener el vector de una palabra que no existe en el modelo\n",
    "try:\n",
    "    vec_cameroon = wv['cameroon']\n",
    "except KeyError:\n",
    "    print(\"La palabra 'cameroon' no existe en este modelo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfd6e7c",
   "metadata": {},
   "source": [
    "### 4.4 Similitud entre Palabras\n",
    "\n",
    "Word2Vec nos permite calcular la **similitud coseno** entre pares de palabras. Observa cómo la similitud disminuye intuitivamente a medida que las palabras son menos relacionadas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7ea61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparamos la similitud entre diferentes pares de palabras\n",
    "pares = [\n",
    "    ('car', 'minivan'),    # una minivan es un tipo de auto\n",
    "    ('car', 'bicycle'),    # aún es un vehículo con ruedas\n",
    "    ('car', 'airplane'),   # un vehículo, pero sin ruedas\n",
    "    ('car', 'cereal'),     # sin relación aparente\n",
    "    ('car', 'communism'),  # conceptos totalmente diferentes\n",
    "]\n",
    "for w1, w2 in pares:\n",
    "    print(f'{w1:15s} {w2:15s} similitud: {wv.similarity(w1, w2):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6cbdde",
   "metadata": {},
   "source": [
    "### 4.5 Palabras Más Similares\n",
    "\n",
    "Podemos encontrar las palabras más cercanas a un concepto dado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befe5101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Las 5 palabras más similares a 'car' y 'minivan'\n",
    "print(\"Palabras más similares a 'car' + 'minivan':\")\n",
    "for palabra, similitud in wv.most_similar(positive=['car', 'minivan'], topn=5):\n",
    "    print(f\"  {palabra}: {similitud:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60b9081",
   "metadata": {},
   "source": [
    "### 4.6 Detección de Intrusos\n",
    "\n",
    "Word2Vec puede identificar qué palabra **no pertenece** a un grupo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff82dca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ¿Cuál de estas palabras no encaja con las demás?\n",
    "intruso = wv.doesnt_match(['fire', 'water', 'land', 'sea', 'air', 'car'])\n",
    "print(f\"La palabra que no pertenece al grupo es: '{intruso}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85dad38",
   "metadata": {},
   "source": [
    "## 5. Entrenar Tu Propio Modelo\n",
    "\n",
    "Ahora viene la parte más importante: **entrenar un modelo Word2Vec con tus propios datos**.\n",
    "\n",
    "### 5.1 Preparar los Datos\n",
    "\n",
    "Word2Vec necesita como entrada un iterable de oraciones, donde cada oración es una lista de palabras (tokens). Usaremos el **Lee Evaluation Corpus** incluido en Gensim.\n",
    "\n",
    "Implementamos un iterador que lee el corpus línea por línea, lo cual es eficiente en memoria para corpus grandes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592a35d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath\n",
    "from gensim import utils\n",
    "\n",
    "class MiCorpus:\n",
    "    \"\"\"Iterador que produce oraciones (listas de palabras).\"\"\"\n",
    "\n",
    "    def __iter__(self):\n",
    "        ruta_corpus = datapath('lee_background.cor')\n",
    "        for linea in open(ruta_corpus):\n",
    "            # Asumimos un documento por línea, tokens separados por espacios\n",
    "            yield utils.simple_preprocess(linea)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2b215c",
   "metadata": {},
   "source": [
    "### 5.2 Entrenar el Modelo\n",
    "\n",
    "Entrenar un modelo Word2Vec con Gensim es sorprendentemente simple. Todo el preprocesamiento personalizado (minúsculas, eliminación de números, etc.) se puede hacer dentro del iterador — Word2Vec solo necesita que la entrada produzca listas de palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd8a13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.models\n",
    "\n",
    "# Creamos el iterador del corpus\n",
    "oraciones = MiCorpus()\n",
    "\n",
    "# Entrenamos el modelo Word2Vec\n",
    "modelo = gensim.models.Word2Vec(sentences=oraciones)\n",
    "print(\"¡Modelo entrenado exitosamente!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d703f399",
   "metadata": {},
   "source": [
    "### 5.3 Usar el Modelo Entrenado\n",
    "\n",
    "Una vez entrenado, podemos usar nuestro modelo de la misma forma que el modelo pre-entrenado. Los vectores de palabras están en `modelo.wv` (\"wv\" = *word vectors*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6444e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener el vector de una palabra\n",
    "vec_king = modelo.wv['king']\n",
    "print(f\"Vector de 'king' (primeros 10 valores): {vec_king[:10]}\")\n",
    "\n",
    "# Ver las primeras 10 palabras del vocabulario\n",
    "print(\"\\nPrimeras 10 palabras del vocabulario:\")\n",
    "for index, word in enumerate(modelo.wv.index_to_key):\n",
    "    if index == 10:\n",
    "        break\n",
    "    print(f\"  #{index}: {word}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdb6c28",
   "metadata": {},
   "source": [
    "## 6. Guardar y Cargar Modelos\n",
    "\n",
    "Entrenar modelos puede tomar tiempo, así que es importante poder **guardarlos en disco** y reutilizarlos después sin volver a entrenar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dea1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "with tempfile.NamedTemporaryFile(prefix='modelo-gensim-', delete=False) as tmp:\n",
    "    ruta_temporal = tmp.name\n",
    "    # Guardar el modelo en disco\n",
    "    modelo.save(ruta_temporal)\n",
    "    print(f\"Modelo guardado en: {ruta_temporal}\")\n",
    "\n",
    "    # Cargar el modelo desde disco\n",
    "    modelo_cargado = gensim.models.Word2Vec.load(ruta_temporal)\n",
    "    print(\"Modelo cargado exitosamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6948a0",
   "metadata": {},
   "source": [
    "También es posible cargar modelos creados con la herramienta original en C:\n",
    "\n",
    "```python\n",
    "# Formato texto\n",
    "modelo = gensim.models.KeyedVectors.load_word2vec_format('/ruta/vectores.txt', binary=False)\n",
    "\n",
    "# Formato binario (también acepta archivos comprimidos .gz o .bz2)\n",
    "modelo = gensim.models.KeyedVectors.load_word2vec_format('/ruta/vectores.bin.gz', binary=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40496310",
   "metadata": {},
   "source": [
    "## 7. Parámetros de Entrenamiento\n",
    "\n",
    "Word2Vec acepta varios parámetros que afectan tanto la velocidad como la calidad del entrenamiento. Entender estos parámetros es clave para obtener buenos resultados.\n",
    "\n",
    "### 7.1 `min_count` — Frecuencia Mínima\n",
    "\n",
    "Controla el filtrado del vocabulario. Las palabras que aparecen menos de `min_count` veces se ignoran. Esto elimina errores tipográficos y palabras demasiado raras para las cuales no hay suficientes datos de entrenamiento.\n",
    "\n",
    "- **Valor por defecto:** 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463e23d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solo considerar palabras que aparecen al menos 10 veces\n",
    "modelo_mc = gensim.models.Word2Vec(oraciones, min_count=10)\n",
    "print(f\"Tamaño del vocabulario con min_count=10: {len(modelo_mc.wv)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e78891",
   "metadata": {},
   "source": [
    "### 7.2 `vector_size` — Dimensión de los Vectores\n",
    "\n",
    "Define el número de dimensiones del espacio vectorial. Vectores más grandes pueden capturar relaciones más complejas, pero requieren más datos de entrenamiento y más memoria.\n",
    "\n",
    "- **Valor por defecto:** 100\n",
    "- **Valores típicos:** entre 50 y 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d301ba95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar vectores de 200 dimensiones\n",
    "modelo_vs = gensim.models.Word2Vec(oraciones, vector_size=200)\n",
    "print(f\"Dimensión de los vectores: {modelo_vs.wv.vector_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e5d4f3",
   "metadata": {},
   "source": [
    "### 7.3 `sg` — Seleccionar la Arquitectura\n",
    "\n",
    "Este parámetro selecciona entre las dos arquitecturas de Word2Vec:\n",
    "- `sg=0` → **CBOW** (valor por defecto)\n",
    "- `sg=1` → **Skip-gram**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fbe32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar con Skip-gram\n",
    "modelo_sg = gensim.models.Word2Vec(oraciones, sg=1)\n",
    "print(\"Modelo entrenado con arquitectura Skip-gram\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241f97c9",
   "metadata": {},
   "source": [
    "### 7.4 `workers` — Paralelización\n",
    "\n",
    "Controla el número de hilos de CPU utilizados durante el entrenamiento. Más hilos = entrenamiento más rápido (requiere Cython instalado).\n",
    "\n",
    "- **Valor por defecto:** 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2079fb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar usando 4 hilos\n",
    "modelo_w = gensim.models.Word2Vec(oraciones, workers=4)\n",
    "print(\"Modelo entrenado con 4 hilos de CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ff0135",
   "metadata": {},
   "source": [
    "### 7.5 Uso de Memoria\n",
    "\n",
    "La memoria requerida por Word2Vec depende de dos factores:\n",
    "\n",
    "- **Tamaño del vocabulario** (controlado por `min_count`)\n",
    "- **Dimensión de los vectores** (`vector_size`)\n",
    "\n",
    "La fórmula aproximada es:\n",
    "\n",
    "$$\\text{Memoria} \\approx \\text{vocabulario} \\times \\text{vector\\_size} \\times 4 \\text{ bytes} \\times 3 \\text{ matrices}$$\n",
    "\n",
    "Por ejemplo, con 100,000 palabras y `vector_size=200`:\n",
    "\n",
    "$$100{,}000 \\times 200 \\times 4 \\times 3 = 240 \\text{ MB}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc68ff2b",
   "metadata": {},
   "source": [
    "## 8. Evaluación del Modelo\n",
    "\n",
    "Word2Vec es un modelo **no supervisado**, por lo que no existe una métrica universal para evaluarlo. Sin embargo, hay dos enfoques comunes:\n",
    "\n",
    "### 8.1 Analogías de Palabras\n",
    "\n",
    "Google publicó un conjunto de pruebas con ~20,000 analogías sintácticas y semánticas del tipo *\"A es a B como C es a D\"*:\n",
    "\n",
    "- **Sintácticas:** `malo:peor :: bueno:?` → mejor\n",
    "- **Semánticas:** `París:Francia :: Tokio:?` → Japón"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8b0368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el modelo con analogías de palabras\n",
    "resultados_analogias = modelo.wv.evaluate_word_analogies(datapath('questions-words.txt'))\n",
    "print(f\"Precisión en analogías: {resultados_analogias[0]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f731d597",
   "metadata": {},
   "source": [
    "### 8.2 Similitud entre Pares de Palabras\n",
    "\n",
    "Otro enfoque utiliza el dataset **WS-353**, que contiene pares de palabras con puntuaciones de similitud asignadas por humanos. Medimos qué tan bien las similitudes del modelo correlacionan con los juicios humanos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ae7d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar con el dataset de similitud WS-353\n",
    "resultados_pares = modelo.wv.evaluate_word_pairs(datapath('wordsim353.tsv'))\n",
    "print(f\"Correlación de Pearson: {resultados_pares[0][0]:.4f}\")\n",
    "print(f\"Correlación de Spearman: {resultados_pares[1][0]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7bb208",
   "metadata": {},
   "source": [
    "> **Importante:** Un buen desempeño en estos benchmarks no garantiza que el modelo funcione bien en tu tarea específica. Siempre es mejor evaluar directamente en tu aplicación final."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb96fee",
   "metadata": {},
   "source": [
    "## 9. Entrenamiento Incremental\n",
    "\n",
    "Es posible cargar un modelo existente y **continuar entrenándolo** con nuevas oraciones y vocabulario adicional:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1745cb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el modelo previamente guardado\n",
    "modelo = gensim.models.Word2Vec.load(ruta_temporal)\n",
    "\n",
    "# Nuevas oraciones para continuar el entrenamiento\n",
    "nuevas_oraciones = [\n",
    "    ['los', 'usuarios', 'avanzados', 'pueden', 'cargar', 'un', 'modelo',\n",
    "     'y', 'continuar', 'entrenando', 'con', 'mas', 'oraciones'],\n",
    "]\n",
    "\n",
    "# Actualizar el vocabulario con nuevas palabras\n",
    "modelo.build_vocab(nuevas_oraciones, update=True)\n",
    "\n",
    "# Continuar el entrenamiento\n",
    "modelo.train(nuevas_oraciones, total_examples=modelo.corpus_count, epochs=modelo.epochs)\n",
    "print(\"Entrenamiento incremental completado\")\n",
    "\n",
    "# Limpiar el archivo temporal\n",
    "import os\n",
    "os.remove(ruta_temporal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6188db",
   "metadata": {},
   "source": [
    "> **Nota:** No es posible continuar el entrenamiento de modelos cargados con `KeyedVectors.load_word2vec_format()`, ya que estos no contienen la información del árbol de vocabulario necesaria para el entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fd613e",
   "metadata": {},
   "source": [
    "## 10. Cálculo de la Pérdida (Loss) durante el Entrenamiento\n",
    "\n",
    "Podemos monitorear la pérdida durante el entrenamiento activando el parámetro `compute_loss`. Esto nos ayuda a verificar que el modelo está aprendiendo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a1891a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar con cálculo de pérdida activado\n",
    "modelo_con_loss = gensim.models.Word2Vec(\n",
    "    oraciones,\n",
    "    min_count=1,\n",
    "    compute_loss=True,\n",
    "    hs=0,\n",
    "    sg=1,   # Usamos Skip-gram\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "# Obtener el valor de la pérdida del entrenamiento\n",
    "perdida = modelo_con_loss.get_latest_training_loss()\n",
    "print(f\"Pérdida del entrenamiento: {perdida:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e620ca3",
   "metadata": {},
   "source": [
    "## 11. Visualización de los Embeddings\n",
    "\n",
    "Una forma intuitiva de entender lo que Word2Vec ha aprendido es **visualizar los vectores en 2D** usando la técnica t-SNE (*t-Distributed Stochastic Neighbor Embedding*).\n",
    "\n",
    "En una buena visualización deberías poder observar:\n",
    "- **Agrupaciones semánticas:** palabras como \"perro\", \"gato\", \"vaca\" aparecen juntas\n",
    "- **Agrupaciones sintácticas:** palabras como \"correr\", \"corriendo\" están cerca\n",
    "- **Relaciones vectoriales:** `vec(rey) - vec(hombre) ≈ vec(reina) - vec(mujer)`\n",
    "\n",
    "> **Nota:** El modelo está entrenado con un corpus pequeño, por lo que las relaciones pueden no ser tan claras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a37e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import IncrementalPCA    # Reducción inicial\n",
    "from sklearn.manifold import TSNE                   # Reducción final a 2D\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def reducir_dimensiones(modelo):\n",
    "    \"\"\"Reduce los embeddings a 2 dimensiones usando t-SNE.\"\"\"\n",
    "    num_dimensiones = 2\n",
    "\n",
    "    # Extraer los vectores y las etiquetas como arrays de NumPy\n",
    "    vectores = np.asarray(modelo.wv.vectors)\n",
    "    etiquetas = np.asarray(modelo.wv.index_to_key)\n",
    "\n",
    "    # Reducir dimensionalidad con t-SNE\n",
    "    tsne = TSNE(n_components=num_dimensiones, random_state=0)\n",
    "    vectores = tsne.fit_transform(vectores)\n",
    "\n",
    "    x_vals = [v[0] for v in vectores]\n",
    "    y_vals = [v[1] for v in vectores]\n",
    "    return x_vals, y_vals, etiquetas\n",
    "\n",
    "\n",
    "x_vals, y_vals, etiquetas = reducir_dimensiones(modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552df7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graficar_con_plotly(x_vals, y_vals, etiquetas, en_notebook=True):\n",
    "    \"\"\"Visualiza los embeddings usando Plotly (interactivo).\"\"\"\n",
    "    from plotly.offline import init_notebook_mode, iplot, plot\n",
    "    import plotly.graph_objs as go\n",
    "\n",
    "    traza = go.Scatter(x=x_vals, y=y_vals, mode='text', text=etiquetas)\n",
    "    datos = [traza]\n",
    "\n",
    "    if en_notebook:\n",
    "        init_notebook_mode(connected=True)\n",
    "        iplot(datos, filename='embedding-palabras')\n",
    "    else:\n",
    "        plot(datos, filename='embedding-palabras.html')\n",
    "\n",
    "\n",
    "def graficar_con_matplotlib(x_vals, y_vals, etiquetas):\n",
    "    \"\"\"Visualiza los embeddings usando Matplotlib (estático).\"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import random\n",
    "\n",
    "    random.seed(0)\n",
    "\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.scatter(x_vals, y_vals)\n",
    "    plt.title('Visualización de Embeddings Word2Vec (t-SNE)')\n",
    "    plt.xlabel('Dimensión 1')\n",
    "    plt.ylabel('Dimensión 2')\n",
    "\n",
    "    # Etiquetar 25 puntos seleccionados al azar\n",
    "    indices = list(range(len(etiquetas)))\n",
    "    indices_seleccionados = random.sample(indices, 25)\n",
    "    for i in indices_seleccionados:\n",
    "        plt.annotate(etiquetas[i], (x_vals[i], y_vals[i]))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def _nbformat_disponible(min_major=4, min_minor=2):\n",
    "    try:\n",
    "        import nbformat\n",
    "        partes = nbformat.__version__.split('.')\n",
    "        major = int(partes[0])\n",
    "        minor = int(partes[1]) if len(partes) > 1 else 0\n",
    "        return (major, minor) >= (min_major, min_minor)\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "\n",
    "# Seleccionar la función de graficación apropiada\n",
    "try:\n",
    "    get_ipython()\n",
    "    en_notebook = True\n",
    "except Exception:\n",
    "    en_notebook = False\n",
    "\n",
    "if en_notebook and _nbformat_disponible():\n",
    "    funcion_graficar = graficar_con_plotly\n",
    "else:\n",
    "    if en_notebook:\n",
    "        print('nbformat>=4.2.0 no está disponible; usando Matplotlib como alternativa.')\n",
    "    funcion_graficar = graficar_con_matplotlib\n",
    "\n",
    "funcion_graficar(x_vals, y_vals, etiquetas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c304be8b",
   "metadata": {},
   "source": [
    "## 12. Resumen y Conceptos Clave\n",
    "\n",
    "En este tutorial aprendimos:\n",
    "\n",
    "| Concepto | Descripción |\n",
    "|---|---|\n",
    "| **Bolsa de Palabras** | Representación simple que pierde orden y significado |\n",
    "| **Word2Vec** | Genera embeddings que capturan relaciones semánticas |\n",
    "| **Skip-gram** | Predice el contexto a partir de una palabra central |\n",
    "| **CBOW** | Predice la palabra central a partir del contexto |\n",
    "| **Similitud coseno** | Mide qué tan parecidos son dos vectores |\n",
    "| **t-SNE** | Técnica para visualizar vectores de alta dimensión en 2D |\n",
    "\n",
    "### Parámetros más importantes:\n",
    "- `vector_size`: Dimensión de los embeddings (más grande = más expresivo, pero necesita más datos)\n",
    "- `min_count`: Frecuencia mínima para incluir una palabra\n",
    "- `sg`: 0 para CBOW, 1 para Skip-gram\n",
    "- `workers`: Número de hilos para paralelizar el entrenamiento\n",
    "\n",
    "### Enlaces útiles:\n",
    "- [Documentación de Gensim Word2Vec](https://radimrehurek.com/gensim/models/word2vec.html)\n",
    "- [Artículos originales de Word2Vec por Google](https://code.google.com/archive/p/word2vec/)\n",
    "- [Tutorial visual de Word2Vec (Jay Alammar)](https://jalammar.github.io/illustrated-word2vec/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Parte 3: Aplicación de Word2Vec al Dataset de Libros\n",
    "\n",
    "Ahora que comprendemos cómo funciona Word2Vec, vamos a aplicar esta técnica al dataset de libros de LibraryThing que utilizamos en la Parte 1.\n",
    "\n",
    "La idea es:\n",
    "1. Tratar los conceptos (features) de cada libro como \"palabras\" y cada libro como una \"oración\"\n",
    "2. Entrenar un modelo Word2Vec sobre estas \"oraciones\" para obtener embeddings de conceptos\n",
    "3. Representar cada libro como el promedio de los embeddings de sus conceptos\n",
    "4. Usar esta nueva representación para el modelo de recomendación y comparar con TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 1: Preparar los datos como \"oraciones\" de conceptos\n",
    "\n",
    "Cada libro tiene un conjunto de conceptos de DBpedia asociados. Vamos a crear una lista de \"oraciones\" donde cada oración es la lista de nombres cortos de conceptos (featureShortname) de un libro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Crear una lista de oraciones a partir de los conceptos de cada libro\n",
    "# Cada oración debe ser una lista de strings con los featureShortname de un libro\n",
    "# Hint: Agrupe df_libros_concepto por DBbook_ItemID y recolecte los featureShortname\n",
    "\n",
    "oraciones_libros = (\n",
    "    df_libros_concepto\n",
    "    .groupby('DBbook_ItemID')['featureShortname']\n",
    "    .apply(list)\n",
    "    .tolist()\n",
    ")\n",
    "\n",
    "print(f'Número de libros (oraciones): {len(oraciones_libros)}')\n",
    "print(f'Ejemplo de oracion (primer libro): {oraciones_libros[0][:10]}...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 2: Entrenar un modelo Word2Vec con los conceptos de los libros\n",
    "\n",
    "**Complete la celda siguiente** entrenando un modelo Word2Vec con los parámetros que considere apropiados. Considere:\n",
    "- `vector_size`: ¿cuántas dimensiones? (pruebe con 50 o 100)\n",
    "- `window`: ¿qué tamaño de ventana? (los conceptos de un libro no tienen orden estricto)\n",
    "- `min_count`: ¿frecuencia mínima?\n",
    "- `sg`: ¿Skip-gram o CBOW?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.models\n",
    "\n",
    "# TODO: Entrene el modelo Word2Vec con las oraciones de conceptos de libros\n",
    "# modelo_w2v = gensim.models.Word2Vec(\n",
    "#     sentences=oraciones_libros,\n",
    "#     vector_size=???,\n",
    "#     window=???,\n",
    "#     min_count=???,\n",
    "#     sg=???,\n",
    "#     workers=4\n",
    "# )\n",
    "\n",
    "modelo_w2v = ???\n",
    "\n",
    "print(f'Vocabulario del modelo: {len(modelo_w2v.wv)} conceptos')\n",
    "print(f'Dimensión de los embeddings: {modelo_w2v.wv.vector_size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 3: Explorar los embeddings aprendidos\n",
    "\n",
    "Verifique que los embeddings tienen sentido buscando conceptos similares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Explore los embeddings aprendidos\n",
    "# Pruebe buscando los conceptos más similares a algún concepto del vocabulario\n",
    "# Ejemplo: modelo_w2v.wv.most_similar('Novel', topn=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 4: Representar cada libro como el promedio de sus embeddings\n",
    "\n",
    "Para obtener un vector por libro, calculamos el **promedio** de los embeddings de todos sus conceptos. Esto nos da una representación densa de cada libro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Crear la matriz de representación de libros usando Word2Vec\n",
    "# Para cada libro, calcule el promedio de los embeddings de sus conceptos\n",
    "\n",
    "def obtener_embedding_libro(item_id, modelo_wv, df_libros_concepto):\n",
    "    \"\"\"Calcula el embedding promedio de un libro a partir de sus conceptos.\"\"\"\n",
    "    conceptos = df_libros_concepto.loc[\n",
    "        df_libros_concepto.DBbook_ItemID == item_id, 'featureShortname'\n",
    "    ].unique()\n",
    "    vectores = []\n",
    "    for c in conceptos:\n",
    "        if c in modelo_wv.key_to_index:\n",
    "            vectores.append(modelo_wv[c])\n",
    "    if vectores:\n",
    "        return np.mean(vectores, axis=0)\n",
    "    else:\n",
    "        return np.zeros(modelo_wv.vector_size)\n",
    "\n",
    "\n",
    "# Construir la matriz de embeddings para todos los libros\n",
    "ids_libros = df_libros['DBbook_ItemID'].values\n",
    "embeddings_libros = np.array([\n",
    "    obtener_embedding_libro(item_id, modelo_w2v.wv, df_libros_concepto)\n",
    "    for item_id in ids_libros\n",
    "])\n",
    "\n",
    "df_matriz_w2v = pd.DataFrame(embeddings_libros, index=ids_libros)\n",
    "print(f'Forma de la matriz Word2Vec: {df_matriz_w2v.shape}')\n",
    "df_matriz_w2v.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 5: Entrenar el modelo KNN con representación Word2Vec\n",
    "\n",
    "**Complete la celda siguiente** para entrenar un clasificador KNN usando la representación Word2Vec en lugar de TF-IDF, y evalúe los resultados para un usuario de ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Repita el proceso de clasificación usando la representación Word2Vec\n",
    "# 1. Seleccione un usuario del conjunto de test\n",
    "# 2. Obtenga sus items de entrenamiento y test\n",
    "# 3. Asocie la representación Word2Vec (df_matriz_w2v) en lugar de TF-IDF\n",
    "# 4. Entrene un KNeighborsClassifier\n",
    "# 5. Evalúe con confusion_matrix y precision_recall_fscore_support\n",
    "\n",
    "# Ejemplo de estructura:\n",
    "# usuario_ejemplo = ???\n",
    "# df_train_w2v = df_all_interactions_train.loc[\n",
    "#     df_all_interactions_train.DBbook_userID == usuario_ejemplo, ['DBbook_ItemID', 'class']\n",
    "# ].merge(df_matriz_w2v, how='left', left_on='DBbook_ItemID', right_index=True)\n",
    "#\n",
    "# df_test_w2v = df_all_interactions_test.loc[\n",
    "#     df_all_interactions_test.DBbook_userID == usuario_ejemplo, ['DBbook_ItemID', 'class']\n",
    "# ].merge(df_matriz_w2v, how='left', left_on='DBbook_ItemID', right_index=True)\n",
    "#\n",
    "# features_w2v = df_matriz_w2v.columns\n",
    "# knn_w2v = KNeighborsClassifier(3)\n",
    "# knn_w2v.fit(df_train_w2v[features_w2v], df_train_w2v['class'])\n",
    "# df_test_w2v['predict'] = knn_w2v.predict(df_test_w2v[features_w2v])\n",
    "#\n",
    "# tn, fp, fn, tp = confusion_matrix(df_test_w2v['class'], df_test_w2v['predict'], labels=[False, True]).ravel()\n",
    "# print('Confusion matrix:', tn, fp, fn, tp)\n",
    "# print(precision_recall_fscore_support(df_test_w2v['class'], df_test_w2v['predict'], pos_label=True, average='binary'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Comparación: TF-IDF vs Word2Vec para Filtrado por Contenido\n",
    "\n",
    "Ahora que ha implementado ambos enfoques, compare los resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio: Evaluación comparativa\n",
    "\n",
    "1. Ejecute el modelo KNN con representación TF-IDF y Word2Vec para al menos 50 usuarios\n",
    "2. Calcule el precision, recall y f-score promedio para cada representación\n",
    "3. Compare los resultados y discuta cuál representación funciona mejor y por qué"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implemente la evaluación comparativa entre TF-IDF y Word2Vec\n",
    "# Calcule las métricas promedio para ambos modelos sobre múltiples usuarios\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio de reflexión: Comparación de estrategias\n",
    "\n",
    "Responda las siguientes preguntas basándose en los resultados obtenidos:\n",
    "\n",
    "1. ¿Cuál representación obtuvo mejores resultados? ¿Por qué cree que es así?\n",
    "2. ¿Cuáles son las ventajas computacionales de cada enfoque? (dimensionalidad, tiempo de entrenamiento, memoria)\n",
    "3. ¿En qué escenarios sería más apropiado usar TF-IDF vs Word2Vec?\n",
    "4. ¿Cómo se podrían aplicar estas representaciones en un esquema de **Filtrado Colaborativo**? (Hint: piense en Item2Vec, donde las secuencias de ítems consumidos por un usuario se tratan como oraciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escriba sus respuestas aquí como comentarios\n",
    "# Respuesta 1:\n",
    "\n",
    "# Respuesta 2:\n",
    "\n",
    "# Respuesta 3:\n",
    "\n",
    "# Respuesta 4:\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv (3.13.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
