{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OKs7ShWIKKi7"
   },
   "source": [
    "# MINE 4201 - Laboratorio 2 - Filtrado por contenido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VnmkMaHMrV-P"
   },
   "source": [
    "Los sistemas de recomendación basados en contenido filtran contenido basado en la representación de items y el perfil del usuario. En este laboratorio trabajaremos con un conjunto de datos del sitio web [LibraryThing](https://https://www.librarything.com/).\n",
    "\n",
    "\n",
    "## Preparación del entorno\n",
    "Instale las librerias que vamos a utilizar e importelas en el ambiente de ejecución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j2IE3mtIuoLG"
   },
   "outputs": [],
   "source": [
    "!pip install scikit-learn\n",
    "!pip install pandas\n",
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kc5uvt4FwPeY"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yqQtNiS4vCJ8"
   },
   "source": [
    "## Carga de archivos\n",
    "\n",
    "Copie el archivo del dataset en el entorno colab en la pestaña files (la carpeta en el menú de la izquierda), carguemos el csv en un dataframe de pandas y revisemos su contenido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hBgLrcbXu4VV"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('DB-BOOK-content.csv') :\n",
    "  raise ValueError('El archivo DB-BOOK-content.csv no fue encontrado en el path')\n",
    "else:\n",
    "  print(\"Los archivos han sido cargados\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7RA_mj5ZxN8w"
   },
   "outputs": [],
   "source": [
    "df_dbbook=pd.read_csv('DB-BOOK-content.csv', sep=';')\n",
    "df_dbbook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wB8U14SC_qzm"
   },
   "source": [
    "Este dataset tiene un formato similar al que manejamos el taller pasado. Tiene una columna con el id del usuario, otra con el id del item y un rating.\n",
    "\n",
    "Cada rating esta presente varias veces, una por cada característica de los libros, revisemos por ejemplo las características del libro con ID 8010.\n",
    "\n",
    "Se selecciona del dataframe las columnas name, featureID y featureShortname, la instruccion drop_duplicates nos deja solamente las columnas que no\n",
    "\n",
    "Nota: Para saber más de indexación de dataframes de pandas utilizando .loc hay una explicación en la [documentación](https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-K8PljKX8MhJ"
   },
   "outputs": [],
   "source": [
    "df_dbbook.loc[df_dbbook.DBbook_ItemID==8010,['DBbook_ItemID','name','featureID','featureShortname']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hxv8YvaiMrPM"
   },
   "source": [
    "Cada libro tiene features que fueron extraidos de [DBpedia](https://wiki.dbpedia.org/). Dbpedia es una iniciativa para construir una representación de conceptos y relaciones mediante ontologías utilizando la información depositada en wikipedia. Más adelante vamos a utilizar DBPedia para otros talleres que aprovechan la información de la ontología de DBPedia, por ahora lo que tenemos es una representación de conjunto de palabras (o conceptos) para describir un item.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AeZn60fcT-OC"
   },
   "source": [
    "## Creación de matriz documento-termino\n",
    "\n",
    "En las siguientes líneas vamos a crear la matriz documento término, el primer paso es obtener en un dataframe los libros, los conceptos, y  los conceptos únicos por libro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8y198APzhd8U"
   },
   "outputs": [],
   "source": [
    "df_libros=df_dbbook.loc[:,['DBbook_ItemID','name']].drop_duplicates()\n",
    "df_libros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kMxSgYFeh5xC"
   },
   "outputs": [],
   "source": [
    "df_conceptos=df_dbbook.loc[:,['featureID','featureShortname']].drop_duplicates()\n",
    "df_conceptos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tXWiCYifMqnr"
   },
   "outputs": [],
   "source": [
    "df_libros_concepto=df_dbbook.loc[:,['DBbook_ItemID','name','featureID','featureShortname']].drop_duplicates()\n",
    "df_libros_concepto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yCw8uuvAXylr"
   },
   "source": [
    "Se quiere obtener una martiz que tenga como filas cada uno de los libros, y como columnas cada uno de los conceptos, y en cada coordenada un 1 si esta presente el concepto y 0 de lo contrario. A esta operación se le conoce como pivot de una tabla.\n",
    "\n",
    "La función [pivot](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.pivot.html) toma tres parámetros: la columna del dataframe original que va a tomar el índice de las filas del nuevo dataframe (index), la columna del dataframe original mediante la cual se van a generar las columnas (columns) y values los valores con los cuales se va a llenar el dataframe, en este caso  vamos a dejar momentaneamente el id del feature para indicar que existe.\n",
    "\n",
    "Finalmente aplicamos la función [notna](https://pandas.pydata.org/docs/reference/api/pandas.notna.html) para modificar uno a uno los elementos de la matriz\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_matriz_libros_concepto = (\n",
    "    df_libros_concepto[['DBbook_ItemID', 'featureID']]\n",
    "      .drop_duplicates()\n",
    "      .pivot(index='DBbook_ItemID', columns='featureID', values='featureID')\n",
    "      .notna()              # vectorized (fast)\n",
    "      .astype('int8')       # 1/0 in int8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matriz_libros_concepto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TkPuSt24UTCF"
   },
   "outputs": [],
   "source": [
    "df_matriz_libros_concepto.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qbHHztT_OI8f"
   },
   "source": [
    "En la siguiente celda se está aplicando la función [sumatoria](https://www.geeksforgeeks.org/python-pandas-dataframe-sum/) por eje al dataframe anterior, por defecto el eje es 0, por lo que generará una Serie (vector) del tamaño de las columnas y por cada columna calculará la sumatoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kzOcvNAR9h_J"
   },
   "outputs": [],
   "source": [
    "help(pd.DataFrame.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TuhKo_lLZd4U"
   },
   "outputs": [],
   "source": [
    "series_suma=df_matriz_libros_concepto.sum()\n",
    "series_suma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ceDsHNaXTlYk"
   },
   "source": [
    "El objeto series_suma no es un dataframe sino un objeto tipo Series, que es un arreglo. Un dataframe puede ser visto como una concatenación de varios objetos de tipo Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BqIJoQulTdhW"
   },
   "outputs": [],
   "source": [
    "type(series_suma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mDO_1AqmfAXq"
   },
   "source": [
    "**Interprete las siguientes figuras y diga qué quieren decir en términos del número de items y de características asignadas a los items**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k0e3niVqdRU7"
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x=range(0,len(series_suma)) ,y=series_suma.sort_values() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RH9SPa1RcCg6"
   },
   "outputs": [],
   "source": [
    "series_suma_2=df_matriz_libros_concepto.sum(axis=1)\n",
    "series_suma_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AaVYz0MGd3hS"
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x=range(0, len(series_suma_2)), y=series_suma_2.sort_values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZECBhVmYikdo"
   },
   "source": [
    "# Cálculo de matriz tf-idf\n",
    "\n",
    "La matriz df_matriz_libros_concepto hasta el momento tiene en cada coordenada la presencia o ausencia de la característica que describe el atributo, este sería el término $\\text{tf}$ de la siguiente fórmula donde $i$ es un término o palabra y $d$ es un documento.\n",
    "\n",
    "$\\text{tfidf}_{i,d} = \\text{tf}_{i,d} \\cdot \\text{idf}_{i}$\n",
    "\n",
    "El Inverse Document Frequency esta definido como:\n",
    "\n",
    "$\\text{idf}_{i,d} = \\log \\frac{N}{\\text{df}_{i}}$\n",
    "\n",
    "Donde $\\text{df}_{t}$ es el número de documentos en los que aparece el término $i$ y N el número total de documentos\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "scSusoGhP-Y-"
   },
   "source": [
    "En python es posible operar vectores con escalares directamente, gracias a que por debajo python genera operaciones entre arreglos cuando operamos con un escalar mediante la operación de [broadcasting](https://jakevdp.github.io/PythonDataScienceHandbook/02.05-computation-on-arrays-broadcasting.html) Por ejemplo, el anterior arreglo se puede dividir entre 6, por debajo python genera un arreglo del mismo tamaño y realiza la operación elemento a elemento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QPaJm6-HNfng"
   },
   "outputs": [],
   "source": [
    "series_suma/6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vk8kecfgTTP7"
   },
   "source": [
    "En las siguientes celdas, cree un objeto tipo series llamado df_idf, que contiene el IDF de cada atributo. Puede utilizar la función [np.log2](https://docs.scipy.org/doc/numpy/reference/generated/numpy.log2.html) de numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FtKa4d7XTOEx"
   },
   "outputs": [],
   "source": [
    "df_idf=???\n",
    "df_idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tBQhrEL-U381"
   },
   "source": [
    "Si df_idf fue calculado correctamente, la siguiente instrucción multiplicará cada fila del dataframe elemento por elemento (element-wise) por la serie que contiene el IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mOq3GJd7UWs7"
   },
   "outputs": [],
   "source": [
    "df_matriz_tf_idf=df_matriz_libros_concepto.multiply(df_idf, axis=1)\n",
    "df_matriz_tf_idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zys6_IxogUAR"
   },
   "source": [
    "En el siguiente mapa de calor se observa el tf_idf de los items representados en las 300 características con mayor frecuencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gEVlmVrqh-PJ"
   },
   "outputs": [],
   "source": [
    "df_matriz_tf_idf.loc[:,series_suma.nlargest(300).index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YURPa2NuUsar"
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (15,15)\n",
    "sns.heatmap(df_matriz_tf_idf.loc[:,series_suma.nlargest(300).index],cmap=\"Blues\", vmin=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sQnyh7YmlhQA"
   },
   "source": [
    "**¿Qué puede interpretar sobre la figura anterior?\n",
    "Encuentre los nombres de las características más frecuentes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HESUWI7Wn3Dw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bIx0A7I4n3Q-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ljppu_vUm_S2"
   },
   "source": [
    "# Selección de características\n",
    "\n",
    "Una vez realizado el proceso de indexamiento, se puede realizar el proceso de selección de características.\n",
    "\n",
    "En este momento contamos con más de 12 mil conceptos. ¿Con cuántos vale la pena crear los modelos de filtrado?\n",
    "\n",
    "El paso más simple es filtrar las características con baja frecuencia dentro del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v5aqEuxwYKRZ"
   },
   "outputs": [],
   "source": [
    "series_suma.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dzO-nEUjp8EX"
   },
   "source": [
    "**¿Qué puede decir sobre la distribución de frecuencia de las características en los items? ¿Vale la pena tener todas las características que tenemos actualmente?**\n",
    "\n",
    ".\n",
    "**Retire de la matriz df_matrix_tf_idf las columnas que representan a los items que tienen menos de 3 items asociados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_HrDjFGNp6tf"
   },
   "outputs": [],
   "source": [
    "# Se filtra la serie por aquellos que tienen al menos 3\n",
    "series_suma[series_suma>=3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N_96kKMLowAz"
   },
   "outputs": [],
   "source": [
    "df_matriz_tf_idf=???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c9oTh99Ksd2E"
   },
   "outputs": [],
   "source": [
    "df_matriz_tf_idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PLrz5tmBsn3G"
   },
   "source": [
    "### Para las siguientes estrategias de selección de características, tenemos que aplicar técnicas supervisadas (que conocen la clase a predecir o lo que se quiere pronosticar), para esto tenemos que retomar nuestro dataset original de interacciones entre usuarios e items para asignar la etiqueta (le gustó/ no le gustó)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L7LPIbBrskLy"
   },
   "outputs": [],
   "source": [
    "# Recordemos como es el dataset original.\n",
    "df_dbbook.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tYJ9ei1auLxc"
   },
   "source": [
    "Creemos un dataframe para crear un dataset de un sistema de recomendación como el visto en el laboratorio pasado (una única interacción de tipo usuario, item y rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4ANyHv11thhi"
   },
   "outputs": [],
   "source": [
    "df_all_interactions=df_dbbook[['DBbook_userID','DBbook_ItemID','rate']].drop_duplicates()\n",
    "df_all_interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xsyZc8bXvMLN"
   },
   "source": [
    "Para asignar una clase, se binarizan los ratings. Una regla simple es calcular el rating promedio por persona. Todo lo que esté por debajo del promedio se clasifica como no le gusta, igual o por encima es si le gusta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AYFPgnafuvOR"
   },
   "outputs": [],
   "source": [
    "df_user_mean=df_all_interactions.groupby('DBbook_userID')['rate'].mean().reset_index()\n",
    "df_user_mean.columns=['DBbook_userID','mean']\n",
    "df_user_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cUjFc_W2xWKE"
   },
   "source": [
    "**Realice un merge entre df_all_interactions y df_user_mean, asignando su resultado a df_all_interactions.\n",
    "Cree una nueva columna en el dataframe df_all_interactions llamada 'class' con True si el rating del usuario es mayor o igual a su promedio**\n",
    "\n",
    "[Documentación pandas merge](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html)\n",
    "\n",
    "[Tutorial creación de columnas a partir del valor de otras](https://thispointer.com/python-pandas-how-to-add-new-columns-in-a-dataframe-using-or-dataframe-assign/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cFalHJy4wiZA"
   },
   "outputs": [],
   "source": [
    "df_all_interactions=???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HpR5vLBsxTyS"
   },
   "outputs": [],
   "source": [
    "df_all_interactions['class']=???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2jrhOGwJyJtw"
   },
   "outputs": [],
   "source": [
    "df_all_interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g0TaHQ5UzBAM"
   },
   "source": [
    "Por último, se procede a partir el dataset en entrenamiento y test. Se utiliza de la librería sklearn la función [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html).\n",
    "\n",
    "Esta recibe como parámetro el dataset a partir, el porcentaje para test y un parámetro que indica la variable por la cual estratificar la partición, en este caso quisieramos que las interacciones en test sean de usuarios que vimos en train, por lo tanto se deja estratificado por usuario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_qjRBWLK9ag3"
   },
   "outputs": [],
   "source": [
    "help(train_test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A_rJHAXnyQOQ"
   },
   "outputs": [],
   "source": [
    "#Para garantizar reproducibilidad en resultados\n",
    "seed = 10\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "df_all_interactions_train, df_all_interactions_test =train_test_split(df_all_interactions, test_size=0.2, stratify=df_all_interactions['DBbook_userID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wm7RE_HE029u"
   },
   "outputs": [],
   "source": [
    "df_all_interactions_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gol-lLxk04KP"
   },
   "outputs": [],
   "source": [
    "df_all_interactions_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IHo1of0bOsac"
   },
   "outputs": [],
   "source": [
    "df_all_interactions_train.DBbook_userID.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OkwMwoKlOgkF"
   },
   "outputs": [],
   "source": [
    "df_all_interactions_test.DBbook_userID.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5h4TZuz5PFkU"
   },
   "outputs": [],
   "source": [
    "df_conteos_usuario_train_test=pd.concat([df_all_interactions_train.DBbook_userID.value_counts(),df_all_interactions_test.DBbook_userID.value_counts()],axis=1)\n",
    "df_conteos_usuario_train_test.columns=['train_count','test_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W8xqph4MP99v"
   },
   "outputs": [],
   "source": [
    "df_conteos_usuario_train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xjlqB-nYQDtH"
   },
   "outputs": [],
   "source": [
    "df_conteos_usuario_train_test.nlargest(500,'test_count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lrz-WIwc6VKM"
   },
   "source": [
    "**Chi-cuadrado**\n",
    "\n",
    "La selección de características mediante la prueba [chi-cuadrado](https://en.wikipedia.org/wiki/Chi-squared_test) nos dice si la diferencia observada entre las frecuencias de co-ocurrencia de dos variables es significativa. La idea es seleccionar características que más ayuden a discriminar la clase objetivo observando la frecuencia en la que ocurren juntas.\n",
    "\n",
    "La librería sklearn permite identificar la importancia de cada una de las variables utilizando el método [chi2](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.chi2.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z2VftVGI06T-"
   },
   "outputs": [],
   "source": [
    "help(chi2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GqPWbi5c-GH2"
   },
   "source": [
    "En filtrado por contenido, se arma un modelo por usuario. Por ahora vamos a escoger las características más importantes para el primer usuario del dataset de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_0cAoMuU9XJ7"
   },
   "outputs": [],
   "source": [
    "#Debería dar 2817\n",
    "primer_usuario_id=df_all_interactions_test.iloc[0]['DBbook_userID']\n",
    "primer_usuario_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YhSkCDyc-f_A"
   },
   "source": [
    "Obtengamos los ids de los items con los que ha interactuado y su opinion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7sHn5myK9ttr"
   },
   "outputs": [],
   "source": [
    "df_temporal_usuario=df_all_interactions_train.loc[df_all_interactions_train.DBbook_userID==1124,['DBbook_ItemID','class']]\n",
    "df_temporal_usuario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x3olsl9JAiqf"
   },
   "source": [
    "Peguemos a este dataframe la representación vectorial de tf_idf por el id del item, en la matriz es el índice de las filas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n-baZRsWAdSa"
   },
   "outputs": [],
   "source": [
    "df_temporal_usuario=df_temporal_usuario.merge(df_matriz_tf_idf, how='left', left_on='DBbook_ItemID', right_index=True)\n",
    "df_temporal_usuario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OeUVr32EBVHf"
   },
   "source": [
    "Este dataframe representa los datos de entrenamiento del modelo para predicción de una clase binaria (class True es le gusta, class False es no le gusta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cg9LICZ8EY_Y"
   },
   "outputs": [],
   "source": [
    "#vamos a indexar solamente las columnas que son características, la prueba chi2 lo compara todas las características contra la clase objetivo\n",
    "features=df_matriz_tf_idf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wLtYVC6bBKAq"
   },
   "outputs": [],
   "source": [
    "pesos_chi2, pval= chi2(df_temporal_usuario[features],df_temporal_usuario['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A-yWyvKqCq4J"
   },
   "outputs": [],
   "source": [
    "#La prueba puede arrojar nan\n",
    "pesos_chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TTetd36rCtNZ"
   },
   "outputs": [],
   "source": [
    "pval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lcG-LgPJEjBZ"
   },
   "outputs": [],
   "source": [
    "# LLenamos con peso 0 los que no se pudieron calcular\n",
    "pesos_chi2=np.nan_to_num(pesos_chi2)\n",
    "pesos_chi2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KtzHpO7GGl7A"
   },
   "source": [
    "Se crea una máscara de indexación con los valores que son positivos según la prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WJaQ-BTcFgzI"
   },
   "outputs": [],
   "source": [
    "pesos_chi2_mask=pesos_chi2>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NV5CGeWjGdMY"
   },
   "outputs": [],
   "source": [
    "pesos_chi2_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BN2UPiY8GekY"
   },
   "outputs": [],
   "source": [
    "features[pesos_chi2_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3jRpP0WyIwPk"
   },
   "source": [
    "El siguiente sería el resultado, se recortaron las columnas de pesos del usuario, dejando 119 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eqQWy2JjGxUY"
   },
   "outputs": [],
   "source": [
    "df_temporal_usuario.loc[:,features[pesos_chi2_mask]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0A9R37kVIrzE"
   },
   "outputs": [],
   "source": [
    "del df_temporal_usuario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XLUTb5TxI7kv"
   },
   "source": [
    "**Complete el código de la siguiente celda, el objetivo es crear un diccionario donde la llave es el id del usuario y el valor es un arreglo con los features seleccionados para el usuario**\n",
    "\n",
    "El proceso que implementamos no esta optimizado, por lo que vamos a armar el modelo solamente para los 500 usuarios con más ratings en el dataset de test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T8EUnhJDIjTt"
   },
   "outputs": [],
   "source": [
    "diccionario_usuarios_features={}\n",
    "# 500 usuarios con más ratings en test\n",
    "unique_users_test=df_conteos_usuario_train_test.nlargest(500,'test_count').index\n",
    "i=0\n",
    "print(unique_users_test.shape)\n",
    "for user in unique_users_test:\n",
    "  if not user in diccionario_usuarios_features:\n",
    "    df_temporal_usuario=df_all_interactions_train.loc[df_all_interactions_train.DBbook_userID==user,['DBbook_ItemID','class']]\n",
    "\n",
    "    df_temporal_usuario=df_temporal_usuario.merge ????\n",
    "\n",
    "    pesos_chi2, pval=????\n",
    "    pesos_chi2=np.nan_to_num(pesos_chi2)\n",
    "    pesos_chi2_mask=pesos_chi2>0\n",
    "    features_usuario=features[pesos_chi2_mask]\n",
    "    diccionario_usuarios_features[user]=features_usuario\n",
    "    i=i+1\n",
    "    if i%50==0:\n",
    "      print(i)\n",
    "    del df_temporal_usuario\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n3go4ywZJOSX"
   },
   "outputs": [],
   "source": [
    "len(diccionario_usuarios_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y1OwnizDbVBG"
   },
   "outputs": [],
   "source": [
    "diccionario_usuarios_features.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hFT8FbvPT4bD"
   },
   "source": [
    "Otro criterio que puede ser usado es [Mutual Information](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_classif.html#sklearn.feature_selection.mutual_info_classif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2kHhHH-_UIn3"
   },
   "source": [
    "# Modelo de recomendación y evaluación\n",
    "\n",
    "Una vez seleccionadas las características por usuario, se puede usar el dataset de entrenamiento para aprender un modelo de clasificación binaria y probarlo sobre test.\n",
    "\n",
    "Uno de los modelos que puede ser utilizado es el [clasificador por vecinos más cercanos](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm).\n",
    "\n",
    "Cada usuario tiene unas instancias representadas en un espacio vectorial del tamaño de las características seleccionadas anteriormente. Para una nueva instancia (predicción) se mira cuáles son los k vecinos más cercanos a ese dato nuevo y se predice la clase mayoritaria dentro del grupo de los vecinos. Observe el siguiente ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hmb-n1W-W5Ch"
   },
   "outputs": [],
   "source": [
    "%%html\n",
    "<iframe src=\"https://es.wikipedia.org/wiki/K_vecinos_m%C3%A1s_pr%C3%B3ximos#/media/Archivo:KnnClassification.svg\" width=\"1200\" height=\"600\"></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kKdEp0MiZ1WL"
   },
   "source": [
    "Tomemos como ejemplo el usuario 3852, armemos su conjunto de entrenamiento. Note que se estan seleccionando solamente los features calculados en el punto anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wLTrU3RBSQ-p"
   },
   "outputs": [],
   "source": [
    "usuario_id = 3852\n",
    "if usuario_id not in diccionario_usuarios_features:\n",
    "    usuario_id = next(iter(diccionario_usuarios_features))\n",
    "    print(f\"Usuario 3852 no disponible en entrenamiento. Se usa usuario {usuario_id}.\")\n",
    "\n",
    "features_usuario = diccionario_usuarios_features[usuario_id]\n",
    "df_temporal_usuario_train = df_all_interactions_train.loc[\n",
    "    df_all_interactions_train.DBbook_userID == usuario_id, ['DBbook_ItemID', 'class']\n",
    " ]\n",
    "df_temporal_usuario_train = df_temporal_usuario_train.merge(\n",
    "    df_matriz_tf_idf[features_usuario], how='left', left_on='DBbook_ItemID', right_index=True\n",
    ")\n",
    "df_temporal_usuario_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W77A4lUtbysX"
   },
   "source": [
    "Armamos de igual forma el conjunto de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HKOUVPhbbpAg"
   },
   "outputs": [],
   "source": [
    "df_temporal_usuario_test = df_all_interactions_test.loc[\n",
    "    df_all_interactions_test.DBbook_userID == usuario_id, ['DBbook_ItemID', 'class']\n",
    " ]\n",
    "df_temporal_usuario_test = df_temporal_usuario_test.merge(\n",
    "    df_matriz_tf_idf[features_usuario], how='left', left_on='DBbook_ItemID', right_index=True\n",
    ")\n",
    "df_temporal_usuario_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eRzxc7DZdWhS"
   },
   "source": [
    "Utilizaremos la clase [KNeighborsClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) de scikit-learn para hacer la predicción de los datos del conjunto de test. El modelo tiene 3 métodos principales. El constructor permite inicializar el k a usar, la métrica entre otros; fit sirve para darle los datos de entrenamiento base al modelo; y predict para predecir los datos que se le pasan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nLrsiGFqe4MQ"
   },
   "outputs": [],
   "source": [
    "#Con esta configuración se utilizan los 3 vecinos más cercanos, con distancia euclidiana\n",
    "knn_clasif=KNeighborsClassifier(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zk--tT6ScodK"
   },
   "outputs": [],
   "source": [
    "# Fit recibe la matriz de entrenamiento y la clase objetivo\n",
    "knn_clasif.fit(df_temporal_usuario_train[features_usuario], df_temporal_usuario_train['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MzXkT1mngNJ4"
   },
   "outputs": [],
   "source": [
    "# llamamos predict sobre  los test , creando una nueva columna en el dataframe de test\n",
    "df_temporal_usuario_test['predict']=knn_clasif.predict(df_temporal_usuario_test[features_usuario])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qQxjEKRShJhV"
   },
   "outputs": [],
   "source": [
    "df_temporal_usuario_test[['DBbook_ItemID','class','predict']].merge(df_libros, how='left', on='DBbook_ItemID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s6uiIgPKjtuf"
   },
   "source": [
    "**En las siguientes celdas realice hipótesis sobre por qué falló la clasificación para estos items y por qué funcionó para los otros, revise los conceptos seleccionados para el usuario y los asociados a los items**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wpTjHFrWj_RO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xagX9J6kj_bi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u6DXNlhwTq5Z"
   },
   "source": [
    "Finalmente, la librería sklearn tiene diferentes métricas de evaluación de clasificación. En particular podemos calcular la matriz de confusión de la clasificación utilizando la función [confusion_matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html), y el cálculo de las métricas precision, recall, y f1 con la función [precision_recall_fscore_support](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gQLtbeNMlFME"
   },
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(df_temporal_usuario_test['class'],df_temporal_usuario_test['predict'], labels=[False,True]).ravel()\n",
    "\n",
    "(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ql_O4aBalNay"
   },
   "outputs": [],
   "source": [
    "precision_recall_fscore_support(df_temporal_usuario_test['class'],df_temporal_usuario_test['predict'], pos_label=True,average='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "96Bh3YlFmuo0"
   },
   "source": [
    "**Ejercicio: Realice las predicciones binarias para los usuarios en el conjunto de test a los que se les hizo la selección de características, mida la precisión, el recall y f_score de su modelo con las predicciones realizadas y ajústelo cambiando el k**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h0Z-k78WmU8G"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv (3.13.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
